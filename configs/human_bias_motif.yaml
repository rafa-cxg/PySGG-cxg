AMP_VERBOSE: false
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
DEBUG: false
DTYPE: float32
EXPERIMENT_NAME: motif
GLOBAL_BUFFER_ON: false
GLOVE_DIR: datasets/vg/stanford_spilt/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 600
  PIXEL_MEAN:
  - 102.9801
  - 115.9465
  - 122.7717
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  SATURATION: 0.0
  TO_BGR255: true
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  TWO_STAGE_ON: true
  TWO_STAGE_HEAD:
    loss_distribution: true
    PURE_SENMENTIC: true
    USE_GLOVE: true #只有在PURE_SEMENTIC为TRUE才起效
    INDIVIDUAL_BOX: false
    UNION_BOX: false  #union和indi不能同时为true
    transformer_pos: false
    HIDDEN_DIM: 1024
    PREDICTOR: TwoStagePredictor
    NUM_REL_GROUP: 50
    BATCH_SIZE_PER_IMAGE: 1000
    POSITIVE_FRACTION: 1
    LOSS_TYPE: 'cos_loss' # 仅在loss_dist为true时成立
  ATTRIBUTE_ON: false
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  FLIP_AUG: false
  FPN:
    USE_GN: false
    USE_RELU: false
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1.0e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: false
  MASK_ON: false
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
#  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-50"
  RELATION_ON: true
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN:
      - false
      - false
      - false
      - false
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: false
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: false
  RETINANET_ON: false
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES:
      - 0.25
      - 0.125
      - 0.0625
      - 0.03125
    PREDICTOR: FPNPredictor
    USE_GN: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: true
    NMS_FILTER_DUPLICATES: True
  ROI_RELATION_HEAD:
    use_possibility_merger: false
    USE_GT_BOX: False
    USE_GT_OBJECT_LABEL: False
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1000
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512
    POOLING_ALL_LEVELS: True
    MAX_PROPOSAL_PAIR: 2048
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"

    WORD_EMBEDDING_FEATURES: True
    EDGE_FEATURES_REPRESENTATION: "fusion"
    FREQUENCY_BAIS: True
    PREDICTOR: "MotifPredictor"
    CLASSIFIER: "linear"
    CAUSAL:
      AUXILIARY_LOSS: false
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: false
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      OBJ_PAIR_LABEL_FREQUENCY_BIAS_BRANCH: true
      SEPARATE_SPATIAL: false
      SPATIAL_FOR_VISION: false
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_OBJ_LAYER: 1 #2
    CONTEXT_REL_LAYER: 1 #4
    DATA_RESAMPLING: False
    GEOMETRIC_FEATURES: true
    LABEL_SMOOTHING_LOSS: false
    LONGTAIL_PART_DICT:
      - null
      - b
      - t
      - t
      - t
      - b
      - b
      - b
      - h
      - b
      - t
      - b
      - t
      - t
      - t
      - t
      - b
      - t
      - t
      - b
      - h
      - b
      - h
      - b
      - t
      - b
      - t
      - t
      - t
      - h
      - h
      - h
      - t
      - b
      - t
      - b
      - t
      - t
      - b
      - t
      - b
      - b
      - t
      - b
      - t
      - t
      - b
      - b
      - h
      - b
      - b
    NUM_SAMPLE_PER_GT_REL: 4
    OBJECT_CLASSIFICATION_MANNER: replace
    OBJECT_CLASSIFICATION_REFINE: false
    PREDICT_USE_BIAS: true
    PREDICT_USE_VISION: true
    REL_OBJ_MULTI_TASK_LOSS: true
    REQUIRE_BOX_OVERLAP: false
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64

  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
SOLVER:
  BASE_LR: 0.008
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 4000
  CLIP_NORM: 5.0
  GAMMA: 0.5
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 9
  MAX_ITER: 70000
  MOMENTUM: 0.9
  PRE_VAL: false
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.8
    MAX_DECAY_STEP: 400
    PATIENCE: 6
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS:
    - 40000
  TO_VAL: true
  UPDATE_SCHEDULE_DURING_LOAD: false
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 1.0e-05
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: false
  BBOX_AUG:
    ENABLED: false
    H_FLIP: false
    MAX_SIZE: 4000
    SCALES: [ ]
    SCALE_H_FLIP: false
  DETECTIONS_PER_IMG: 80
  EXPECTED_RESULTS: [ ]
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 3
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.3
    MULTIPLE_PREDS: false
    REQUIRE_OVERLAP: false
    SYNC_GATHER: true
  SAVE_PROPOSALS: false
OUTPUT_DIR: checkpoints
PATHS_CATALOG: pysgg/config/paths_catalog.py
PATHS_DATA: pysgg/config/../data/datasets




