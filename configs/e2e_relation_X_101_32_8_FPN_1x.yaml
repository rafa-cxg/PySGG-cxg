INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  TWO_STAGE_ON: False
  TWO_STAGE_HEAD:
    loss_distribution: true
    PURE_SENMENTIC: true
    USE_GLOVE: true #只有在PURE_SEMENTIC为TRUE才起效
    INDIVIDUAL_BOX: false
    UNION_BOX: false  #union和indi不能同时为true
    transformer_pos: false
    HIDDEN_DIM: 1024
    PREDICTOR: TwoStagePredictor
    NUM_REL_GROUP: 50
    BATCH_SIZE_PER_IMAGE: 1000
    POSITIVE_FRACTION: 1
    LOSS_TYPE: 'cos_loss' # 仅在loss_dist为true时成立
    DYNAMIC_GT: False #使用可变EEM的GT
    DYNAMIC_GT_FACTOR: 0.5 #原分布的占比
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
#    FOCAL_LOSS:
#      GAMMA: 2.0

    USE_GT_BOX: False
    USE_GT_OBJECT_LABEL: False
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 128      # sample as much as possible
    POSITIVE_FRACTION: 1.0
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    USE_SEM_WORD_EMBEDDING: False
    LANGUAGE_SPATIAL_ATTENTION: False
    CAT_WORD_EMBEDDING: True #whether concat object class embedding
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: False #True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048
    ############### Parameters for DualTransformer Predictor ##############
    BIAS_MODULE:
      USE_PENALTY: False # should be enable when use following,,
      PENALTY_BIAS:
        PENALTY_TYPE: 'count_bias'
    #default base+cb
    DUAL_TRANS :
      USE_GRAPH_ENCODE: True
      GRAPH_ENCODE_STRATEGY: trans


DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.00001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 80000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 4
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.8
    MAX_DECAY_STEP: 24
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5
GLOBAL_SETTING:  #Only for use of SHA MODEL
  ############### Parameters for Basic Encoder in Predictor ##############
  #RELATION_PREDICTOR: "MotifsLikePredictor"
  #RELATION_PREDICTOR: "VCTreePredictor"
  #RELATION_PREDICTOR: "TransLikePredictor"
  #RELATION_PREDICTOR: "MotifsLike_GCL"
  #RELATION_PREDICTOR: "VCTree_GCL"
  RELATION_PREDICTOR: "TransLike_GCL"
  BASIC_ENCODER: 'Hybrid-Attention'
  # ['Self-Attention', 'Cross-Attention', 'Hybrid-Attention'] for Transformer-Based Model, and ['Motifs', 'VTransE'] for DNN-Based Model
  ############### Parameters for Global Settings of Experiment ##############
  DATASET_CHOICE: 'VG'
  USE_BIAS: True                                      # If use the relation statistics to serve as the priori knowledge
  CHOOSE_BEST_MODEL_BY_METRIC: '_mean_recall'         # ['_recall', '_mean_recall'] To control which metric is the main concern
  PRINT_INTERVAL: 100
  ############### Parameters for GCL Loss Setting ##############
  GCL_SETTING:
    GROUP_SPLIT_MODE: 'divide4'                       # To control the number of groups ['divide4', ''divide3', 'divide5', 'average']
    KNOWLEDGE_LOSS_COEFFICIENT: 1.0                   # To control the loss of Knowledge Transfer
    KNOWLEDGE_TRANSFER_MODE: 'KL_logit_TopDown'       # To control how to transfer the knowledge between different auxiliary classifiers
    # ['None', 'KL_logit_Neighbor', 'KL_logit_None', 'KL_logit_TopDown', 'KL_logit_BottomUp', 'KL_logit_BiDirection']
    ############### The Following Parameters would not affect the performance much, is nearly useless ##############
    NO_RELATION_RESTRAIN: True              # If two object do not have a relation, then limit their contribution to the final loss
    ZERO_LABEL_PADDING_MODE: 'rand_insert'  # ['rand_insert', 'rand_choose', 'all_include'], to control how to insert into the relation which is ZERO
    NO_RELATION_PENALTY: 0.1 # only for  GCL